{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pathlib\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import sys\n",
    "sys.path.append('/home/levaid/bigstorage/open_lth')\n",
    "from open_lth import *\n",
    "import torchvision\n",
    "from torch.nn.utils import prune\n",
    "from copy import deepcopy\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) Facebook, Inc. and its affiliates.\n",
    "\n",
    "# This source code is licensed under the MIT license found in the\n",
    "# LICENSE file in the root directory of this source tree.\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from foundations import hparams\n",
    "from lottery.desc import LotteryDesc\n",
    "from models import base\n",
    "from pruning import sparse_global\n",
    "from models import initializers\n",
    "\n",
    "\n",
    "class Model(base.Model):\n",
    "    \"\"\"A VGG-style neural network designed for CIFAR-10.\"\"\"\n",
    "\n",
    "    class ConvModule(nn.Module):\n",
    "        \"\"\"A single convolutional module in a VGG network.\"\"\"\n",
    "\n",
    "        def __init__(self, in_filters, out_filters):\n",
    "            super(Model.ConvModule, self).__init__()\n",
    "            # print([in_filters, out_filters])\n",
    "            self.conv = nn.Conv2d(in_filters, out_filters, kernel_size=3, padding=1)\n",
    "            self.bn = nn.BatchNorm2d(out_filters)\n",
    "\n",
    "        def forward(self, x):\n",
    "            return F.relu(self.bn(self.conv(x)))\n",
    "\n",
    "    def __init__(self, plan, initializer, outputs=10):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        layers = []\n",
    "        filters = 3\n",
    "        print('plan:', plan)\n",
    "        for spec in plan:\n",
    "            if spec == 'M':\n",
    "                layers.append(nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "            else:\n",
    "                # print([filters, spec])\n",
    "                layers.append(Model.ConvModule(filters, spec))\n",
    "                filters = spec\n",
    "\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        self.fc = nn.Linear(512, outputs)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        self.apply(initializer)\n",
    "\n",
    "        self.grads = {}\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        x = nn.AvgPool2d(2)(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "    def prune_network_sparse(self, pruning_ratio):\n",
    "        weights_on_important_layers = []\n",
    "        for name, module in self.named_modules():\n",
    "            if 'conv' in name or 'fc' in name:\n",
    "                # print(name)\n",
    "                weights_on_important_layers += [np.abs(module.weight.detach().cpu().numpy().flatten())]\n",
    "\n",
    "        weights = np.concatenate(weights_on_important_layers)\n",
    "        threshold = np.percentile(weights, (1-pruning_ratio)*100)\n",
    "        for name, module in self.named_modules():\n",
    "            if 'conv' in name or 'fc' in name:\n",
    "                # print(name)\n",
    "                prune.custom_from_mask(module, name = 'weight', \n",
    "                                       mask = (torch.abs(module.weight) > torch.tensor(threshold, device=device)).to(device))\n",
    "                \n",
    "        return(threshold)\n",
    "    \n",
    "    def prune_network_snip(self, pruning_ratio):\n",
    "        weights_on_important_layers = []\n",
    "        for name, module in self.named_modules():\n",
    "            if 'conv' in name or 'fc' in name:\n",
    "                # print(name)\n",
    "                weights_on_important_layers += [np.abs((module.weight.detach().cpu().numpy() *\n",
    "                                                        self.grads[name+'.weight']).flatten())]\n",
    "\n",
    "        weights = np.concatenate(weights_on_important_layers)\n",
    "        threshold = np.percentile(weights, (1-pruning_ratio)*100)\n",
    "        for name, module in self.named_modules():\n",
    "            if 'conv' in name or 'fc' in name:\n",
    "                # print(name)\n",
    "                prune.custom_from_mask(module, name = 'weight', \n",
    "                                       mask = (torch.abs(module.weight.detach().cpu() * self.grads[name+'.weight']) > torch.tensor(threshold, device=device)).to(device))\n",
    "                \n",
    "        return(threshold)\n",
    "\n",
    "    @property\n",
    "    def output_layer_names(self):\n",
    "        return ['fc.weight', 'fc.bias']\n",
    "\n",
    "    @staticmethod\n",
    "    def is_valid_model_name(model_name):\n",
    "        return (model_name.startswith('cifar_vgg_') and\n",
    "                len(model_name.split('_')) == 3 and\n",
    "                model_name.split('_')[2].isdigit() and\n",
    "                int(model_name.split('_')[2]) in [11, 13, 16, 19])\n",
    "\n",
    "    @staticmethod\n",
    "    def get_model_from_name(model_name, initializer, outputs=10):\n",
    "        if not Model.is_valid_model_name(model_name):\n",
    "            raise ValueError('Invalid model name: {}'.format(model_name))\n",
    "\n",
    "        outputs = outputs or 10\n",
    "\n",
    "        num = int(model_name.split('_')[2])\n",
    "        if num == 11:\n",
    "            plan = [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512]\n",
    "        elif num == 13:\n",
    "            plan = [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512]\n",
    "        elif num == 16:\n",
    "            plan = [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512]\n",
    "        elif num == 19:\n",
    "            plan = [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512]\n",
    "        else:\n",
    "            raise ValueError('Unknown VGG model: {}'.format(model_name))\n",
    "\n",
    "        return Model(plan, initializer, outputs)\n",
    "\n",
    "    @property\n",
    "    def loss_criterion(self):\n",
    "        return self.criterion\n",
    "\n",
    "    @staticmethod\n",
    "    def default_hparams():\n",
    "        model_hparams = hparams.ModelHparams(\n",
    "            model_name='cifar_vgg_16',\n",
    "            model_init='kaiming_normal',\n",
    "            batchnorm_init='uniform',\n",
    "        )\n",
    "\n",
    "        dataset_hparams = hparams.DatasetHparams(\n",
    "            dataset_name='cifar10',\n",
    "            batch_size=128\n",
    "        )\n",
    "\n",
    "        training_hparams = hparams.TrainingHparams(\n",
    "            optimizer_name='sgd',\n",
    "            momentum=0.9,\n",
    "            milestone_steps='80ep,120ep',\n",
    "            lr=0.1,\n",
    "            gamma=0.1,\n",
    "            weight_decay=1e-4,\n",
    "            training_steps='160ep'\n",
    "        )\n",
    "\n",
    "        pruning_hparams = sparse_global.PruningHparams(\n",
    "            pruning_strategy='sparse_global',\n",
    "            pruning_fraction=0.2,\n",
    "            pruning_layers_to_ignore='fc.weight'\n",
    "        )\n",
    "\n",
    "        return LotteryDesc(model_hparams, dataset_hparams, training_hparams, pruning_hparams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "train_dataset = CIFAR10('/home/levaid/bigstorage/open_lth_datasets/cifar10', train=True, download=True,\n",
    "                                transform=torchvision.transforms.Compose([torchvision.transforms.ToTensor()]))\n",
    "test_dataset = CIFAR10('/home/levaid/bigstorage/open_lth_datasets/cifar10', train=False, download=True,\n",
    "                                transform=torchvision.transforms.Compose([torchvision.transforms.ToTensor()]))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plan: [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512]\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "original_model = Model.get_model_from_name('cifar_vgg_11', initializers.kaiming_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020_06_18_23_17_21_snip_init\n"
     ]
    }
   ],
   "source": [
    "LEVELS = 10\n",
    "PRUNING_RATIO = 0.5\n",
    "EPOCHS = 60\n",
    "\n",
    "currentDT = datetime.datetime.now()\n",
    "\n",
    "EXPERIMENT_NAME = currentDT.strftime(\"%Y_%m_%d_%H_%M_%S\") + '_snip_init'\n",
    "print(EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(os.path.join('/home/levaid/bigstorage/open_lth_data/', EXPERIMENT_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "5.881160494583884e-14\n",
      "test_accuracy,0,0.5543\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-6a5d76f21dd0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m                         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "performance_metrics = []\n",
    "for level in range(LEVELS):\n",
    "    \n",
    "    model = deepcopy(original_model)\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr = 0.1, momentum=0.1)\n",
    "\n",
    "    current_ratio = PRUNING_RATIO ** (level)\n",
    "\n",
    "    print(current_ratio)\n",
    "    for ep in range(EPOCHS):\n",
    "        model.train()\n",
    "        \n",
    "        for it, (examples, labels) in enumerate(train_loader):\n",
    "            examples = examples.to(device=device)\n",
    "            labels = labels.to(device=device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            loss = model.loss_criterion(model(examples), labels)\n",
    "\n",
    "            for name, layer in model.named_parameters():\n",
    "                if layer.requires_grad:\n",
    "                    layer.retain_grad()\n",
    "                    \n",
    "\n",
    "            loss.backward()\n",
    "            \n",
    "            \n",
    "\n",
    "            for name, layer in model.named_parameters():\n",
    "                if layer.requires_grad:\n",
    "                    if name in model.grads:\n",
    "                        model.grads[name] += layer.grad.clone().cpu().numpy()\n",
    "                    else:\n",
    "                        model.grads[name] = layer.grad.clone().cpu().numpy()\n",
    "                    # print(layer.grad)\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "        if ep == 0:\n",
    "            threshold = model.prune_network_snip(current_ratio)\n",
    "            print(threshold)\n",
    "\n",
    "        correct = 0\n",
    "        model.eval()\n",
    "        for it, (examples, labels) in enumerate(test_loader):\n",
    "            examples = examples.to(device=device)\n",
    "            labels = labels.to(device=device)\n",
    "            \n",
    "            correct += torch.sum(torch.argmax(model(examples), dim=1) == labels).cpu().numpy()\n",
    "        performance_metrics += [(f'test_accuracy,{ep},{correct/10000.0}')]\n",
    "        print(performance_metrics[-1])\n",
    "\n",
    "        if ep == 40:\n",
    "            print('reducing LR')\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] /= 10\n",
    "        \n",
    "        with open(f'/home/levaid/bigstorage/open_lth_data/{EXPERIMENT_NAME}/level_{level}_perf.log', 'w') as f:\n",
    "            for line in performance_metrics:\n",
    "                f.write(line + '\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[2].conv.weight.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, module in model.named_modules():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.grads.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[0].conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
